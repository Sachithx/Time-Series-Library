{
  "entropy_model": {
    "n_layer": 2,
    "n_head": 4,
    "n_embd": 16,
    "dropout": 0.1,
    "bias": false,
    "vocab_size": 256,
    "block_size": 512
  }
}
